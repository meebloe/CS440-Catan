# Catan AI Project (ML Agent with Unity Integration)

## Overview

This project implements an AI agent using a simple Multi-Layer Perceptron (MLP) neural network to play a 2-player version of the board game Settlers of Catan. The project features:

1.  **Unity Game Client (`client/CatanLearner.exe`):** Runs the Catan game logic, determines legal moves, serializes the game state to JSON, sends it to the AI server, receives the AI's chosen action, and executes it. Supports Human vs. Bot and Bot vs. Bot modes. Generates game logs for training.
2.  **Python AI Server (`server/catan_ai.py`):** A Flask server that receives game state JSON, vectorizes it (`server/game_state_encoder.py`), uses a trained PyTorch model (`server/model.py`) to predict the best action among the available legal moves (provided by the client), and returns the chosen action JSON.
3.  **Training Pipeline (`server/train_from_logs.py`):** A script to train the PyTorch model using game logs generated by the Unity client during self-play (`client/SelfPlayLogs`). Saves the trained model weights (`server/model_weights.pth`).
4.  **Launcher Script (`launch_bot_match.py`):** The main entry point to manage running the game and training the AI in different modes (`play`, `train`, `bulktrain`)

## Project Structure

```text
.
├── README.md
├── client/                 # Unity Game Client and related files
│ ├── CatanLearner.exe      # The executable game client
│ └── ... (Other Unity files/folders)
├── server/                 # Python AI Server, Model, and Training code
│ ├── catan_ai.py           # Flask server handling API requests
│ ├── model.py              # PyTorch MLP model definition
│ ├── game_state_encoder.py # Converts game state JSON to a numerical vector
│ ├── action_mapping.py     # Maps action descriptions to numerical indices
│ ├── train_from_logs.py    # Script to train the model from game logs
│ ├── model_weights.pth     # Saved weights for the trained model
│ ├── iterations/           # Checkpoints saved during bulk training
│ └── ... (init.py)
├── launch_bot_match.py     # Main script to launch game/server and manage modes
├── requirements.txt        # Python dependencies
└── ... (Other potential test/output files)
```

## Prerequisites

*   **Conda (recommended):** For Python environment management. Download and install Anaconda.
*   **Python:** Version 3.9+.
*   **Unity Game Build:** The `client/CatanLearner.exe` built from the Unity project (provided here).

## Setup

1.  **Clone the Repository:**
    ```bash
    git clone <https://github.com/meebloe/CS440-Catan.git>
    cd catan_ai_project
    ```

2.  **Create and Activate Conda Environment:**
    Open your terminal or Anaconda Prompt.
    ```bash
    # Create the environment (python >= 3.10)
    conda create --name catan_ai_env python=3.12

    # Activate the environment
    conda activate catan_ai_env
    ```

3.  **Install Dependencies:**
    While the environment is active, install the required Python packages using `requirements.txt`:
    ```bash
    pip install -r requirements.txt
    ```
    *(This will install Flask, PyTorch, NumPy, etc...)*

    or

    ```bash
    conda install --yes --file requirements.txt
    ```
    *(This will install dependencies, however torch does not provide a conda installation and may need to be installed separately)*

## How to Run

Use the `launch_bot_match.py` script from the project root directory while your `catan_ai_env` conda environment is active.

### Basic Modes

1.  **Play Mode (Human vs. AI):**
    *   Launches the AI server.
    *   Launches the Unity game configured for a human player (Player 0) against the AI bot (Player 1) (graphical mode by default).
    *   After the game finishes, it runs a quick training pass on the log generated from that single game (using a higher learning rate).
    ```bash
    conda activate catan_ai_env
    python launch_bot_match.py play
    ```

2.  **Training Mode (Bot vs. Bot - Multiple Games):**
    *   Clears previous logs (moves them to `client/OldLogs/`).
    *   Launches the AI server in `TRAIN` mode (enables exploration during inference).
    *   Launches the specified number (`n`) of Unity games concurrently, configured for Bot vs. Bot self-play (headless mode by default).
    *   Waits for all games to complete (or timeout).
    *   Runs the training script (`train_from_logs.py`) on *all* logs generated in the `client/SelfPlayLogs/` directory from this batch of games (using a normal learning rate).
    *   Saves the updated `model_weights.pth`.
    ```bash
    conda activate catan_ai_env
    python launch_bot_match.py train <n_games>
    ```
    *(Replace `<n_games>` with the number of games to play, e.g., `python launch_bot_match.py train 5`)*

3.  **Bulk Training Mode (Iterative Bot vs. Bot):**
    *   Designed for longer unsupervised training cycles.
    *   Clears previous logs.
    *   Launches the AI server.
    *   **Repeats `num_sets` times:**
        *   Runs `games_per_set` concurrent Bot vs. Bot games (headless mode by default).
        *   Waits for the games to finish (or timeout).
        *   Trains the model on the logs from those games.
        *   Saves a checkpoint of the model weights to the `server/iterations/` folder (e.g., `settlerbot_1.pth`, `settlerbot_2.pth`, ...).
        *   Clears the logs before the next set.
    ```bash
    conda activate catan_ai_env
    python launch_bot_match.py bulktrain <games_per_set> <num_sets>
    ```
    *(Replace `<games_per_set>` with the number of games per set, and `<num_sets>` with the number of sets/iterations. E.g., `python launch_bot_match.py bulktrain 10 5` runs 10 games, trains, checkpoints, clears logs, and repeats this 5 times.)*

### Optional Arguments

You can customize the execution using optional command-line flags, typically added after the mode and its specific arguments:

*   `--timeout SECONDS`: Sets the maximum duration for a single game in seconds (default: 300).
*   `--force-headless`: Forces all game instances to run in headless mode (no graphics window, using `-batchmode -nographics`). Useful for running `play` mode without the UI.
*   `--force-graphical`: Forces all game instances to run with graphics enabled (no headless flags). Useful for watching a `train` or `bulktrain` game.
*   `--unity-exe PATH`: Specifies a different path for the `CatanLearner.exe` file.
*   `--server-script PATH`: Specifies a different path for the `catan_ai.py` server script.
*   `--train-script PATH`: Specifies a different path for the `train_from_logs.py` script.
*   `--model-weights PATH`: Specifies a different path for the `model_weights.pth` file (both loading and saving).
*   `-h` or `--help`: Shows a help message detailing all modes and optional arguments, then exits.

**Example combining mode and optional arguments:**

```bash
# Run 5 training games, force graphical mode, and set a longer timeout
python launch_bot_match.py train 5 --force-graphical --timeout 600
```

## Training Process

*   **Log Generation:** When the Unity client runs in Bot vs. Bot mode (`train` or `bulktrain`), it saves detailed logs of each game turn (state, action taken, reward) as `.jsonl` files in `client/SelfPlayLogs/`.
*   **Training Script:** `server/train_from_logs.py` reads all `.jsonl` files in the log directory.
*   **Data Conversion:** For each recorded turn, it vectorizes the `state` using `game_state_encoder.py` and gets the numerical index of the `action` using `action_mapping.py`. It also uses the recorded `reward` (potentially adding a bonus for winning moves).
*   **Model Update:** It trains the `CatanSimpleMLP` model defined in `server/model.py` using the collected (state_vector, action_index, reward) tuples. It uses an MSELoss function, treating it somewhat like a Q-learning update where the target for the taken action is the observed reward.
*   **Weight Saving:** After training epochs, the updated model weights are saved to `server/model_weights.pth`. In `bulktrain` mode, numbered checkpoints are also saved in `server/iterations/`.
*   **Log Clearing:** The `launch_bot_match.py` script moves processed logs from `SelfPlayLogs` to `OldLogs` after training to prevent re-training on the same data in subsequent runs.

## JSON Communication Format

Communication between the game client (Unity) and the AI server (Python Flask) uses JSON objects sent over HTTP POST requests to the `/get_action` endpoint.

### 1. State JSON (Sent from Game Client to AI Server)

This JSON object represents the complete snapshot of the game state needed for the AI to make a decision.

**Structure:**

```javascript
{
  "gameStateId": "string (optional)",   // Unique identifier (ignored by encoder, useful for logging)
  "currentPlayerIndex": integer,        // Index (0 or 1) of the player whose turn it is
  "diceResult": integer,                // Result of the last dice roll (2-12). 0 or other value if not applicable/rolled yet.
  "hexes": [                            // List of 19 hex objects (MUST be in consistent order, matching NUM_HEXES)
    {
      "id": integer,                    // Hex index (0-18)
      "resource": "string" | null,      // Resource type ("WOOD", "BRICK", "SHEEP", "WHEAT", "STONE", "DESERT") or null
      "numberToken": integer | null     // Dice number (2-12, excluding 7) or null (for desert)
    },
    // ... 18 more hex objects
  ],
  "roads": [                            // List of 72 potential road edge objects (MUST be in consistent order, matching NUM_ROADS)
    {
      "id": integer,                    // Edge index (0-71)
      "ownerPlayerIndex": integer       // Owning player index (0 or 1), or -1 if unoccupied
    },
    // ... 71 more road objects
  ],
  "buildings": [                        // List of 54 potential building intersection objects (MUST be in consistent order, matching NUM_INTERSECTIONS)
    {
      "id": integer,                    // Intersection index (0-53)
      "ownerPlayerIndex": integer,      // Owning player index (0 or 1), or -1 if unoccupied
      "type": "string"                  // Type of building ("NONE", "SETTLEMENT", "CITY")
    },
    // ... 53 more building objects
  ],
  "players": [                          // List of 2 player objects (MUST match NUM_PLAYERS)
    {
      "index": integer,                 // Player index (0 or 1)
      "resources": {                    // Dictionary of resource counts (Keys MUST match RESOURCE_ORDER)
        "WOOD": integer,                // Not using original Catan names yet
        "BRICK": integer,               // Not using original Catan names yet
        "SHEEP": integer,               // Not using original Catan names yet
        "WHEAT": integer,               // Not using original Catan names yet
        "STONE": integer                // Not using original Catan names yet
      },
      "victoryPoints": integer          // Current public victory point count
    },
    { // Player 1 object structure is identical
      "index": 1,
      "resources": { /* ... */ },
      "victoryPoints": integer
    }
  ],
  "availableActions": [                 // List of all moves available to the bot given the current board state
    // Each object in this list represents one possible, valid action.
    // The 'actionType' and keys MUST exactly match those handled in 'server/action_mapping.py'.
    {"actionType": "BUILD_ROAD", "edgeIndex": integer},
    {"actionType": "BUILD_SETTLEMENT", "intersectionIndex": integer},
    {"actionType": "BUILD_CITY", "intersectionIndex": integer}, // Index of the settlement to upgrade
    {"actionType": "BANK_TRADE_4_1", "resourceOut": "string", "resourceIn": "string"}, // Resource names from RESOURCE_ORDER
    {"actionType": "END_TURN"}
    // Note: Actions like MOVE_ROBBER are NOT currently implemented by the Unity game
    // and therefore cannot be processed or chosen by the AI.
  ]
}
```

### 2. Action JSON (Sent from AI Server to Game Client)

The server selects one of the actions provided in the `availableActions` list from the State JSON and returns it in the exact same format.

**Example Response:**

```javascript
{"actionType": "BUILD_ROAD", "edgeIndex": 15}
```

or

```javascript
{"actionType": "END_TURN"}
```